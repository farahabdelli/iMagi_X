{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df):\n",
    "    ''' on utilise year == 2022 pour constituer le dataset de test'''\n",
    "    \n",
    "    train = df.iloc[:106952]\n",
    "    test =  df.iloc[106953:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_modelisation(x_train, y_train):\n",
    "    ''' determination des hyperparametre de RF'''\n",
    "    weights = np.linspace(0.1,0.9,100)\n",
    "    params = [{\n",
    "        \"n_estimators\": [10, 100,150],\n",
    "        \"max_features\": [2, 4, 8,10,12],\n",
    "        \"class_weight\":[{0:x, 1:1.0-x} for x in weights]\n",
    "        }]\n",
    "\n",
    "    rfCV = GridSearchCV(\n",
    "        RandomForestClassifier(),\n",
    "        params,\n",
    "        scoring=\"f1_micro\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True)\n",
    "    \n",
    "    rfCV = rfCV.fit(x_train, y_train)\n",
    "    \n",
    "    return rfCV.best_estimator_\n",
    "\n",
    "#\n",
    "def logist_modelisation(x_train, y_train):\n",
    "    # grille de valeurs\n",
    "    weights = np.linspace(0.1,0.9,100)\n",
    "\n",
    "    params = [{\"C\": [0.01, 0.2, 0.5, 1, 5, 10, 20],\n",
    "           \"penalty\": [\"l1\", \"l2\",\"none\"],\n",
    "           \"class_weight\":[{0:x, 1:1.0-x} for x in weights]\n",
    "          }]\n",
    "\n",
    "    logitCV = GridSearchCV(\n",
    "        LogisticRegression(solver='liblinear'),\n",
    "        params,\n",
    "        scoring=\"f1_micro\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True)\n",
    "    \n",
    "    logitCV = logitCV.fit(x_train, y_train)\n",
    "    \n",
    "    return logitCV.best_estimator_\n",
    "\n",
    "#\n",
    "def OneSVM_modelisation(x_train, y_train):\n",
    "    # grille de valeurs\n",
    "\n",
    "    params = [{\"nu\": [0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.9], \n",
    "              'max_iter': [100,250, 500, 700, 900],\n",
    "           #\"class_weight\":[{0:x, 1:1.0-x} for x in weights]\n",
    "          }]\n",
    "\n",
    "    outlierCV = GridSearchCV(\n",
    "        OneClassSVM(),\n",
    "        params,\n",
    "        scoring=\"f1_micro\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True)\n",
    "    \n",
    "    outlierCV = outlierCV.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    return outlierCV.best_estimator_\n",
    "\n",
    "def DT_modelisation(x_train, y_train):\n",
    "    # grille de valeurs\n",
    "    weights = np.linspace(0.1,0.9,100)\n",
    "\n",
    "    params = [{\n",
    "        \"max_depth\": [3, 5, 10, 15,None],\n",
    "        \"min_samples_split\": [2, 5, 10,15,20,30],\n",
    "        \"min_samples_leaf\": [1, 2, 5,10,15,20,30],\n",
    "        \"class_weight\":[{0:x, 1:1.0-x} for x in weights]\n",
    "        }]\n",
    "\n",
    "    dtCV = GridSearchCV(\n",
    "        DecisionTreeClassifier(),\n",
    "        params,\n",
    "        scoring=\"f1_micro\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True)\n",
    "    \n",
    "    dtCV = dtCV.fit(x_train, y_train)\n",
    "    \n",
    "    return dtCV.best_estimator_\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111482\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "data = pd.read_csv(\"data/all_features.csv\", sep=';',low_memory=False)\n",
    "label = pd.read_csv(\"data/descriptif_hiver_ete.csv\", sep=';',low_memory=False)\n",
    "print(len(data))\n",
    "\n",
    "\n",
    "# definition de train et test \n",
    "# definition de x et y \n",
    "x_train, x_test = train_test(data.iloc[:,1:])\n",
    "train_target,test_target = train_test(label)\n",
    "y_test = test_target['baignade']\n",
    "y_train = train_target['baignade']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "model_logist = logist_modelisation(x_train, y_train)\n",
    "model_logist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(class_weight={0: 0.28585858585858587,\n",
       "                                     1: 0.7141414141414142},\n",
       "                       max_depth=3, min_samples_leaf=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight={0: 0.28585858585858587,\n",
       "                                     1: 0.7141414141414142},\n",
       "                       max_depth=3, min_samples_leaf=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(class_weight={0: 0.28585858585858587,\n",
       "                                     1: 0.7141414141414142},\n",
       "                       max_depth=3, min_samples_leaf=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## decision tree\n",
    "model_dt = DT_modelisation(x_train, y_train)\n",
    "model_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 0.10808080808080808,\n",
       "                                     1: 0.8919191919191919},\n",
       "                       max_features=2, n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 0.10808080808080808,\n",
       "                                     1: 0.8919191919191919},\n",
       "                       max_features=2, n_estimators=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.10808080808080808,\n",
       "                                     1: 0.8919191919191919},\n",
       "                       max_features=2, n_estimators=10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Random forest\n",
    "model_rf = rf_modelisation(x_train, y_train)\n",
    "model_rf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model_dt, \"saved_models/decision_tree.joblib\")\n",
    "joblib.dump(model_rf, \"saved_models/random_forest.joblib\")\n",
    "joblib.dump(model_logist, \"saved_models/reg_logist.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Training data-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29638\n",
      "           1       0.43      0.98      0.60       393\n",
      "\n",
      "    accuracy                           0.98     30031\n",
      "   macro avg       0.72      0.98      0.80     30031\n",
      "weighted avg       0.99      0.98      0.99     30031\n",
      "\n",
      "-------------------------Test data-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      3976\n",
      "           1       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.88      4529\n",
      "   macro avg       0.44      0.50      0.47      4529\n",
      "weighted avg       0.77      0.88      0.82      4529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FABDELLI\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\FABDELLI\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\FABDELLI\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## RF\n",
    "model_rf.fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_train_predict = model_rf.predict(x_train)\n",
    "y_test_predict = model_rf.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"-----------------------Training data-----------------------\")\n",
    "print(classification_report(y_train, y_train_predict))\n",
    "print(\"-------------------------Test data-------------------------\")\n",
    "print(classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Training data-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     29638\n",
      "           1       0.08      0.11      0.10       393\n",
      "\n",
      "    accuracy                           0.97     30031\n",
      "   macro avg       0.54      0.55      0.54     30031\n",
      "weighted avg       0.98      0.97      0.97     30031\n",
      "\n",
      "-------------------------Test data-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      3976\n",
      "           1       0.35      0.21      0.26       553\n",
      "\n",
      "    accuracy                           0.86      4529\n",
      "   macro avg       0.62      0.58      0.59      4529\n",
      "weighted avg       0.83      0.86      0.84      4529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FABDELLI\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_logist.fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_train_predict = model_logist.predict(x_train)\n",
    "y_test_predict = model_logist.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"-----------------------Training data-----------------------\")\n",
    "print(classification_report(y_train, y_train_predict))\n",
    "print(\"-------------------------Test data-------------------------\")\n",
    "print(classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Training data-----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     29638\n",
      "           1       0.53      0.02      0.04       393\n",
      "\n",
      "    accuracy                           0.99     30031\n",
      "   macro avg       0.76      0.51      0.52     30031\n",
      "weighted avg       0.98      0.99      0.98     30031\n",
      "\n",
      "-------------------------Test data-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      3976\n",
      "           1       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.87      4529\n",
      "   macro avg       0.44      0.50      0.47      4529\n",
      "weighted avg       0.77      0.87      0.82      4529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dt.fit(x_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_train_predict = model_dt.predict(x_train)\n",
    "y_test_predict = model_dt.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"-----------------------Training data-----------------------\")\n",
    "print(classification_report(y_train, y_train_predict))\n",
    "print(\"-------------------------Test data-------------------------\")\n",
    "print(classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/decision_tree.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "022a9a6482eaf02d50898206bfe85d505610851c09ba0130f14d4758edb773a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
